#COO = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0 : compressed(nonunique), d1 : singleton(soa)) }>

// Computes: a(i) = B(i,j) * c(j)
func.func @spmv(%B: tensor<{{ rows }}x{{ cols }}xf64, #COO>,
                %c_t: tensor<{{ cols }}xf64>,
                %a_t: tensor<{{ rows }}xf64>) -> tensor<{{ rows }}xf64> {

    %true = arith.constant true
    %false = arith.constant false

    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index

    // Fixed lookahead distance
    %dist = arith.constant {{ pd }} : index
    %double_dist = arith.muli %dist, %c2 : index

    %c = bufferization.to_memref %c_t : memref<{{ cols }}xf64>
    %a = bufferization.to_memref %a_t : memref<{{ rows }}xf64>
    %Bi_pos = sparse_tensor.positions   %B {level = 0 : index} : tensor<{{ rows }}x{{ cols }}xf64, #COO> to memref<?xindex>
    %Bi_crd = sparse_tensor.coordinates %B {level = 0 : index} : tensor<{{ rows }}x{{ cols }}xf64, #COO> to memref<?xindex>
    %Bj_crd = sparse_tensor.coordinates %B {level = 1 : index} : tensor<{{ rows }}x{{ cols }}xf64, #COO> to memref<?xindex>
    %B_vals = sparse_tensor.values %B : tensor<{{ rows }}x{{ cols }}xf64, #COO> to memref<?xf64>
    %6 = memref.load %Bi_pos[%c0] : memref<?xindex>
    %7 = memref.load %Bi_pos[%c1] : memref<?xindex>

    // Finds first segment's upper bound
    %8 = scf.while (%arg3 = %6) : (index) -> index {
      %11 = arith.cmpi ult, %arg3, %7 : index
      %12 = scf.if %11 -> (i1) {
        %13 = memref.load %Bi_crd[%6] : memref<?xindex>
        %14 = memref.load %Bi_crd[%arg3] : memref<?xindex>
        %15 = arith.cmpi eq, %13, %14 : index
        scf.yield %15 : i1
      } else {
        scf.yield %false : i1
      }
      scf.condition(%12) %arg3 : index
    } do {
    ^bb0(%arg3: index):
      %11 = arith.addi %arg3, %c1 : index
      scf.yield %11 : index
    }

    %9:2 = scf.while (%arg3 = %6, %seg_end = %8) : (index, index) -> (index, index) {
      %11 = arith.cmpi ult, %arg3, %7 : index
      scf.condition(%11) %arg3, %seg_end : index, index
    } do {
    ^bb0(%arg3: index, %seg_end: index):
      %11 = memref.load %Bi_crd[%arg3] : memref<?xindex>
      scf.if %true {
        %14 = memref.load %a[%11] : memref<{{ rows }}xf64>
        %15 = scf.for %iB = %arg3 to %seg_end step %c1 iter_args(%arg6 = %14) -> (f64) {

          // Load candidate coordinate j
          %j = memref.load %Bj_crd[%iB] : memref<?xindex>

          // Load B_vals[iB]
          %22 = memref.load %B_vals[%iB] : memref<?xf64>

          // Load c[j]
          %23 = memref.load %c[%j] : memref<{{ cols }}xf64>

          // Prefetch Bj_crd[iB + 2 * dist]
          %17 = arith.addi %iB, %double_dist : index
          memref.prefetch %Bj_crd[%17], read, locality<{{ loc_hint }}>, data : memref<?xindex>

          // Load Bj_crd[min(iB + dist, seg_end)]
          %18 = arith.addi %iB, %dist : index
          %19 = arith.cmpi ult, %18, %c1 : index
          %20 = arith.select %19, %18, %c1 : index
          %21 = memref.load %Bj_crd[%20] : memref<?xindex>

          // Prefetch c[Bj_crd[min(iB + dist, seg_end)]]
          memref.prefetch %c[%21], read, locality<{{ loc_hint }}>, data : memref<{{ cols }}xf64>

          %24 = arith.mulf %22, %23 : f64
          %25 = arith.addf %arg6, %24 : f64
          scf.yield %25 : f64
        } {"Emitted from" = "linalg.generic"}
        memref.store %15, %a[%11] : memref<{{ rows }}xf64>
      } else {
      }
      %13:2 = scf.if %true -> (index, index) {
        %14 = scf.while (%iB = %seg_end) : (index) -> index {
          %15 = arith.cmpi ult, %iB, %7 : index
          %16 = scf.if %15 -> (i1) {
            %17 = memref.load %Bi_crd[%seg_end] : memref<?xindex>
            %18 = memref.load %Bi_crd[%iB] : memref<?xindex>
            %19 = arith.cmpi eq, %17, %18 : index
            scf.yield %19 : i1
          } else {
            scf.yield %false : i1
          }
          scf.condition(%16) %iB : index
        } do {
        ^bb0(%iB: index):
          %15 = arith.addi %iB, %c1 : index
          scf.yield %15 : index
        }
        scf.yield %seg_end, %14 : index, index
      } else {
        scf.yield %arg3, %seg_end : index, index
      }
      scf.yield %13#0, %13#1 : index, index
    } attributes {"Emitted from" = "linalg.generic"}
    %10 = bufferization.to_tensor %a : memref<{{ rows }}xf64>
    return %10 : tensor<{{ rows }}xf64>
}

