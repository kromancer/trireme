#CSR = #sparse_tensor.encoding<{ map = (d0, d1) -> (d0: dense, d1: compressed) }>

module {

func.func @spmv(%vec: tensor<{{ cols }}xf64>,
                %res: tensor<{{ rows }}xf64>,
                %mat: tensor<{{ rows }}x{{ cols }}xf64, #CSR>) -> tensor<{{ rows }}xf64> {

    %pos = sparse_tensor.positions %mat {level = 1 : index} : tensor<{{ rows }}x{{ cols }}xf64, #CSR> to memref<?xindex>
    %crd = sparse_tensor.coordinates %mat {level = 1 : index} : tensor<{{ rows }}x{{ cols }}xf64, #CSR> to memref<?xindex>
    %mat_vals = sparse_tensor.values %mat : tensor<{{ rows }}x{{ cols }}xf64, #CSR> to memref<?xf64>

    %vec_vals = bufferization.to_memref %vec : memref<{{ cols }}xf64>
    %res_buff = bufferization.to_memref %res : memref<{{ rows }}xf64>

    // micro params
    %cl_size_in_indices = arith.constant {{ cl_size_in_indices }} : index
    %l1_mshrs = arith.constant {{ l1_mshrs }} : index
    %l2_mshrs = arith.constant {{ l2_mshrs }} : index

    %num_of_rows = arith.constant {{ rows }} : index
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index

    scf.for %i = %c0 to %num_of_rows step %c1 {
        %init_res_i = memref.load %res_buff[%i] : memref<{{ rows }}xf64>

        // Load j_start
        %j_start = memref.load %pos[%i] : memref<?xindex>

        // Load j_end
        %i_plus_one = arith.addi %i, %c1 : index
        %j_end = memref.load %pos[%i_plus_one] : memref<?xindex>

        // Fill l1 mshrs by fetching l1_mshrs cache lines
            {% for cl_offset in cl_offsets %}
        %cl_offset_{{ cl_offset }} = arith.constant {{ cl_offset }} : index
        %j_start_plus_{{ cl_offset }} = arith.addi %j_start, %cl_offset_{{ cl_offset }} : index
        memref.prefetch %crd[%j_start_plus_{{ cl_offset }}], read, locality<3>, data : memref<?xindex>
            {% endfor %}

        // Fill l2 mshrs by fetching l2_mshr elements
        %j_start_plus_l2_mshrs = arith.addi %j_start, %l2_mshrs : index
        scf.for %l = %j_start to %j_start_plus_l2_mshrs step %c1 {
          %col_idx = memref.load %crd[%l] : memref<?xindex>
          memref.prefetch %vec_vals[%col_idx], read, locality<2>, data : memref<{{ cols }}xf64>
        }

        %num_of_nnz = arith.subi %j_end, %j_start : index
        %num_of_nnz_DIV_cl_size_in_indices = arith.divui %num_of_nnz, %cl_size_in_indices : index
        %num_of_nnz_closest_mult_of_cl_size = arith.muli %num_of_nnz_DIV_cl_size_in_indices, %cl_size_in_indices : index
        %j_end_closest_mult_of_cl_size = arith.addi %j_start, %num_of_nnz_closest_mult_of_cl_size : index

        %partial_res_i = scf.for %j = %j_start to %j_end_closest_mult_of_cl_size step %cl_size_in_indices iter_args(%acc = %init_res_i) -> (f64) {

                {% for index in indices %}
            // Unrolled: iteration {{ index }}
            %c_index_{{ index }} = arith.constant {{ index }} : index
            %j_plus_{{ index }} = arith.addi %j, %c_index_{{ index }} : index
            %col_{{ index }} = memref.load %crd[%j_plus_{{ index }}] : memref<?xindex>
            %mat_{{ index }} = memref.load %mat_vals[%j_plus_{{ index }}] : memref<?xf64>
            %vec_val_{{ index }} = memref.load %vec_vals[%col_{{ index }}] : memref<{{ cols }}xf64>

            %mul_{{ index }} = arith.mulf %mat_{{ index }}, %vec_val_{{ index }} : f64
                    {% if index == 0 %}
            %acc_{{ index }} = arith.addf %acc, %mul_{{ index }} : f64
                    {% else %}
            %acc_{{ index }} = arith.addf %acc_{{ index - 1 }}, %mul_{{ index }} : f64
                    {% endif %}
            %j_plus_{{ index }}_plus_l2_mshrs = arith.addi %j_plus_{{ index }}, %l2_mshrs : index
            memref.prefetch %vec_vals[%j_plus_{{ index }}_plus_l2_mshrs], read, locality<2>, data : memref<{{ cols }}xf64>
                {% endfor %}

            %pref_crd_cl = arith.addi %j_start_plus_{{ cl_offsets[-1] }}, %j : index
            memref.prefetch %crd[%pref_crd_cl], read, locality<3>, data : memref<?xindex>

            scf.yield %acc_{{ cl_size_in_indices -  1 }} : f64
        }

        %res_i = scf.for %j = %j_end_closest_mult_of_cl_size to %j_end step %c1 iter_args(%acc = %partial_res_i) -> (f64) {

            // Load column indices and values for non-zero elements
            %col_idx = memref.load %crd[%j] : memref<?xindex>
            %mat_j = memref.load %mat_vals[%j] : memref<?xf64>
            %vec_val = memref.load %vec_vals[%col_idx] : memref<{{ cols }}xf64>

            // Compute
            %mul = arith.mulf %mat_j, %vec_val : f64
            %partial_res = arith.addf %acc, %mul : f64

            scf.yield %partial_res : f64
        }

        memref.store %res_i, %res_buff[%i] : memref<{{ rows }}xf64>
    }

    %5 = bufferization.to_tensor %res_buff restrict : memref<{{ rows }}xf64>
    return %5 : tensor<{{ rows }}xf64>
}

            {% include "main.mlir.jinja2" %}
}
